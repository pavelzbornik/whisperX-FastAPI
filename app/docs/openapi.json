{
  "openapi": "3.1.0",
  "info": {
    "title": "whisperX REST service",
    "description": "\n# whisperX REST Service\n\nWelcome to the whisperX RESTful API! This API provides a suite of audio processing services to enhance and analyze your audio content.\n\n## Documentation:\n\nFor detailed information on request and response formats, consult the [WhisperX Documentation](https://github.com/m-bain/whisperX).\n\n## Services:\n\nSpeech-2-Text provides a suite of audio processing services to enhance and analyze your audio content. The following services are available:\n\n1. Transcribe: Transcribe an audio/video  file into text.\n2. Align: Align the transcript to the audio/video file.\n3. Diarize: Diarize an audio/video file into speakers.\n4. Combine Transcript and Diarization: Combine the transcript and diarization results.\n\n## Supported file extensions:\nAUDIO_EXTENSIONS = {'.mp3', '.amr', '.wav', '.oga', '.m4a', '.wma', '.awb', '.ogg', '.aac'}\n\nVIDEO_EXTENSIONS = {'.mp4', '.mov', '.avi', '.wmv', '.mkv'}\n\n",
    "version": "0.0.1"
  },
  "paths": {
    "/speech-to-text": {
      "post": {
        "tags": [
          "Speech-2-Text"
        ],
        "summary": "Speech To Text",
        "description": "Process an audio/video file in the background in full process.\n\nArgs:\n    background_tasks (BackgroundTasks): The BackgroundTasks object.\n    audio_file (UploadFile): The audio file to process.\n\nReturns:\n    dict: A dictionary containing the identifier and a message. The message is \"Task queued\". The identifier is a unique identifier for the transcription request.",
        "operationId": "speech_to_text_speech_to_text_post",
        "parameters": [
          {
            "name": "language",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/LanguageEnum"
                }
              ],
              "description": "Language to transcribe",
              "enum": [
                "en",
                "zh",
                "de",
                "es",
                "ru",
                "ko",
                "fr",
                "ja",
                "pt",
                "tr",
                "pl",
                "ca",
                "nl",
                "ar",
                "sv",
                "it",
                "id",
                "hi",
                "fi",
                "vi",
                "he",
                "uk",
                "el",
                "ms",
                "cs",
                "ro",
                "da",
                "hu",
                "ta",
                "no",
                "th",
                "ur",
                "hr",
                "bg",
                "lt",
                "la",
                "mi",
                "ml",
                "cy",
                "sk",
                "te",
                "fa",
                "lv",
                "bn",
                "sr",
                "az",
                "sl",
                "kn",
                "et",
                "mk",
                "br",
                "eu",
                "is",
                "hy",
                "ne",
                "mn",
                "bs",
                "kk",
                "sq",
                "sw",
                "gl",
                "mr",
                "pa",
                "si",
                "km",
                "sn",
                "yo",
                "so",
                "af",
                "oc",
                "ka",
                "be",
                "tg",
                "sd",
                "gu",
                "am",
                "yi",
                "lo",
                "uz",
                "fo",
                "ht",
                "ps",
                "tk",
                "nn",
                "mt",
                "sa",
                "lb",
                "my",
                "bo",
                "tl",
                "mg",
                "as",
                "tt",
                "haw",
                "ln",
                "ha",
                "ba",
                "jw",
                "su",
                "yue"
              ],
              "default": "en",
              "title": "Language"
            },
            "description": "Language to transcribe"
          },
          {
            "name": "task",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/TaskEnum"
                }
              ],
              "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')",
              "default": "transcribe",
              "title": "Task"
            },
            "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')"
          },
          {
            "name": "model",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/WhisperModel"
                }
              ],
              "description": "Name of the Whisper model to use",
              "default": "tiny",
              "title": "Model"
            },
            "description": "Name of the Whisper model to use"
          },
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Device"
                }
              ],
              "description": "Device to use for PyTorch inference",
              "default": "cuda",
              "title": "Device"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "device_index",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Device index to use for FasterWhisper inference",
              "default": 0,
              "title": "Device Index"
            },
            "description": "Device index to use for FasterWhisper inference"
          },
          {
            "name": "threads",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS",
              "default": 0,
              "title": "Threads"
            },
            "description": "Number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS"
          },
          {
            "name": "batch_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "The preferred batch size for inference",
              "default": 8,
              "title": "Batch Size"
            },
            "description": "The preferred batch size for inference"
          },
          {
            "name": "compute_type",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/ComputeType"
                }
              ],
              "description": "Type of computation",
              "default": "float16",
              "title": "Compute Type"
            },
            "description": "Type of computation"
          },
          {
            "name": "align_model",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Name of phoneme-level ASR model to do alignment",
              "title": "Align Model"
            },
            "description": "Name of phoneme-level ASR model to do alignment"
          },
          {
            "name": "interpolate_method",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/InterpolateMethod"
                }
              ],
              "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring.",
              "default": "nearest",
              "title": "Interpolate Method"
            },
            "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring."
          },
          {
            "name": "return_char_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return character-level alignments in the output json file",
              "default": false,
              "title": "Return Char Alignments"
            },
            "description": "Return character-level alignments in the output json file"
          },
          {
            "name": "min_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Minimum number of speakers to in audio file",
              "title": "Min Speakers"
            },
            "description": "Minimum number of speakers to in audio file"
          },
          {
            "name": "max_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Maximum number of speakers to in audio file",
              "title": "Max Speakers"
            },
            "description": "Maximum number of speakers to in audio file"
          },
          {
            "name": "beam_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Beam Size"
            },
            "description": "Number of beams in beam search, only applicable when temperature is zero"
          },
          {
            "name": "patience",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional patience value to use in beam decoding",
              "default": 1.0,
              "title": "Patience"
            },
            "description": "Optional patience value to use in beam decoding"
          },
          {
            "name": "length_penalty",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional token length penalty coefficient",
              "default": 1.0,
              "title": "Length Penalty"
            },
            "description": "Optional token length penalty coefficient"
          },
          {
            "name": "temperatures",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Temperature to use for sampling",
              "default": 0.0,
              "title": "Temperatures"
            },
            "description": "Temperature to use for sampling"
          },
          {
            "name": "compression_ratio_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed",
              "default": 2.4,
              "title": "Compression Ratio Threshold"
            },
            "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed"
          },
          {
            "name": "log_prob_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the average log probability is lower than this value, treat the decoding as failed",
              "default": -1.0,
              "title": "Log Prob Threshold"
            },
            "description": "If the average log probability is lower than this value, treat the decoding as failed"
          },
          {
            "name": "no_speech_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence",
              "default": 0.6,
              "title": "No Speech Threshold"
            },
            "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence"
          },
          {
            "name": "initial_prompt",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Optional text to provide as a prompt for the first window.",
              "title": "Initial Prompt"
            },
            "description": "Optional text to provide as a prompt for the first window."
          },
          {
            "name": "suppress_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "array",
              "items": {
                "type": "integer"
              },
              "description": "Comma-separated list of token ids to suppress during sampling",
              "default": [
                -1
              ],
              "title": "Suppress Tokens"
            },
            "description": "Comma-separated list of token ids to suppress during sampling"
          },
          {
            "name": "suppress_numerals",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "boolean"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Whether to suppress numeric symbols and currency symbols during sampling",
              "default": false,
              "title": "Suppress Numerals"
            },
            "description": "Whether to suppress numeric symbols and currency symbols during sampling"
          },
          {
            "name": "vad_onset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected",
              "default": 0.5,
              "title": "Vad Onset"
            },
            "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected"
          },
          {
            "name": "vad_offset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected.",
              "default": 0.363,
              "title": "Vad Offset"
            },
            "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected."
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_speech_to_text_speech_to_text_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/speech-to-text-url": {
      "post": {
        "tags": [
          "Speech-2-Text"
        ],
        "summary": "Speech To Text Url",
        "operationId": "speech_to_text_url_speech_to_text_url_post",
        "parameters": [
          {
            "name": "language",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "Language to transcribe",
              "enum": [
                "en",
                "zh",
                "de",
                "es",
                "ru",
                "ko",
                "fr",
                "ja",
                "pt",
                "tr",
                "pl",
                "ca",
                "nl",
                "ar",
                "sv",
                "it",
                "id",
                "hi",
                "fi",
                "vi",
                "he",
                "uk",
                "el",
                "ms",
                "cs",
                "ro",
                "da",
                "hu",
                "ta",
                "no",
                "th",
                "ur",
                "hr",
                "bg",
                "lt",
                "la",
                "mi",
                "ml",
                "cy",
                "sk",
                "te",
                "fa",
                "lv",
                "bn",
                "sr",
                "az",
                "sl",
                "kn",
                "et",
                "mk",
                "br",
                "eu",
                "is",
                "hy",
                "ne",
                "mn",
                "bs",
                "kk",
                "sq",
                "sw",
                "gl",
                "mr",
                "pa",
                "si",
                "km",
                "sn",
                "yo",
                "so",
                "af",
                "oc",
                "ka",
                "be",
                "tg",
                "sd",
                "gu",
                "am",
                "yi",
                "lo",
                "uz",
                "fo",
                "ht",
                "ps",
                "tk",
                "nn",
                "mt",
                "sa",
                "lb",
                "my",
                "bo",
                "tl",
                "mg",
                "as",
                "tt",
                "haw",
                "ln",
                "ha",
                "ba",
                "jw",
                "su",
                "yue"
              ],
              "default": "en",
              "title": "Language"
            },
            "description": "Language to transcribe"
          },
          {
            "name": "task",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')",
              "enum": [
                "transcribe",
                "translate"
              ],
              "default": "transcribe",
              "title": "Task"
            },
            "description": "whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')"
          },
          {
            "name": "model",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/WhisperModel"
                }
              ],
              "description": "Name of the Whisper model to use",
              "default": "tiny",
              "title": "Model"
            },
            "description": "Name of the Whisper model to use"
          },
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Device"
                }
              ],
              "description": "Device to use for PyTorch inference",
              "default": "cuda",
              "title": "Device"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "device_index",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Device index to use for FasterWhisper inference",
              "default": 0,
              "title": "Device Index"
            },
            "description": "Device index to use for FasterWhisper inference"
          },
          {
            "name": "batch_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "The preferred batch size for inference",
              "default": 8,
              "title": "Batch Size"
            },
            "description": "The preferred batch size for inference"
          },
          {
            "name": "compute_type",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/ComputeType"
                }
              ],
              "description": "Type of computation",
              "default": "float16",
              "title": "Compute Type"
            },
            "description": "Type of computation"
          },
          {
            "name": "align_model",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "Name of phoneme-level ASR model to do alignment",
              "title": "Align Model"
            },
            "description": "Name of phoneme-level ASR model to do alignment"
          },
          {
            "name": "interpolate_method",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring.",
              "enum": [
                "nearest",
                "linear",
                "ignore"
              ],
              "default": "nearest",
              "title": "Interpolate Method"
            },
            "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring."
          },
          {
            "name": "return_char_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return character-level alignments in the output json file",
              "default": false,
              "title": "Return Char Alignments"
            },
            "description": "Return character-level alignments in the output json file"
          },
          {
            "name": "temperature",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "temperature to use for sampling",
              "default": 0,
              "title": "Temperature"
            },
            "description": "temperature to use for sampling"
          },
          {
            "name": "beam_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "number of beams in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Beam Size"
            },
            "description": "number of beams in beam search, only applicable when temperature is zero"
          },
          {
            "name": "patience",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "optional patience value to use in beam decoding",
              "default": 1.0,
              "title": "Patience"
            },
            "description": "optional patience value to use in beam decoding"
          },
          {
            "name": "length_penalty",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "optional token length penalty coefficient",
              "default": 1.0,
              "title": "Length Penalty"
            },
            "description": "optional token length penalty coefficient"
          },
          {
            "name": "suppress_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "comma-separated list of token ids to suppress during sampling",
              "default": "-1",
              "title": "Suppress Tokens"
            },
            "description": "comma-separated list of token ids to suppress during sampling"
          },
          {
            "name": "suppress_numerals",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "whether to suppress numeric symbols and currency symbols during sampling",
              "default": false,
              "title": "Suppress Numerals"
            },
            "description": "whether to suppress numeric symbols and currency symbols during sampling"
          },
          {
            "name": "initial_prompt",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "optional text to provide as a prompt for the first window.",
              "title": "Initial Prompt"
            },
            "description": "optional text to provide as a prompt for the first window."
          },
          {
            "name": "compression_ratio_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "if the gzip compression ratio is higher than this value, treat the decoding as failed",
              "default": 2.4,
              "title": "Compression Ratio Threshold"
            },
            "description": "if the gzip compression ratio is higher than this value, treat the decoding as failed"
          },
          {
            "name": "logprob_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "if the average log probability is lower than this value, treat the decoding as failed",
              "default": -1.0,
              "title": "Logprob Threshold"
            },
            "description": "if the average log probability is lower than this value, treat the decoding as failed"
          },
          {
            "name": "no_speech_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "if the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence",
              "default": 0.6,
              "title": "No Speech Threshold"
            },
            "description": "if the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence"
          },
          {
            "name": "vad_onset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected",
              "default": 0.5,
              "title": "Vad Onset"
            },
            "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected"
          },
          {
            "name": "vad_offset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected.",
              "default": 0.363,
              "title": "Vad Offset"
            },
            "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected."
          },
          {
            "name": "threads",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS",
              "default": 0,
              "title": "Threads"
            },
            "description": "number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS"
          },
          {
            "name": "min_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Minimum number of speakers to in audio file",
              "title": "Min Speakers"
            },
            "description": "Minimum number of speakers to in audio file"
          },
          {
            "name": "max_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Maximum number of speakers to in audio file",
              "title": "Max Speakers"
            },
            "description": "Maximum number of speakers to in audio file"
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/x-www-form-urlencoded": {
              "schema": {
                "$ref": "#/components/schemas/Body_speech_to_text_url_speech_to_text_url_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/task/all": {
      "get": {
        "tags": [
          "Tasks Management"
        ],
        "summary": "Get All Tasks Status",
        "operationId": "get_all_tasks_status_task_all_get",
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ResultTasks"
                }
              }
            }
          }
        }
      }
    },
    "/task/{identifier}": {
      "get": {
        "tags": [
          "Tasks Management"
        ],
        "summary": "Get Transcription Status",
        "operationId": "get_transcription_status_task__identifier__get",
        "parameters": [
          {
            "name": "identifier",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string",
              "title": "Identifier"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Result"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/task/{identifier}/delete": {
      "delete": {
        "tags": [
          "Tasks Management"
        ],
        "summary": "Delete Task",
        "operationId": "delete_task_task__identifier__delete_delete",
        "parameters": [
          {
            "name": "identifier",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string",
              "title": "Identifier"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/transcribe": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "1. Transcribe",
        "operationId": "1__Transcribe_service_transcribe_post",
        "parameters": [
          {
            "name": "language",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "Language to transcribe",
              "enum": [
                "en",
                "zh",
                "de",
                "es",
                "ru",
                "ko",
                "fr",
                "ja",
                "pt",
                "tr",
                "pl",
                "ca",
                "nl",
                "ar",
                "sv",
                "it",
                "id",
                "hi",
                "fi",
                "vi",
                "he",
                "uk",
                "el",
                "ms",
                "cs",
                "ro",
                "da",
                "hu",
                "ta",
                "no",
                "th",
                "ur",
                "hr",
                "bg",
                "lt",
                "la",
                "mi",
                "ml",
                "cy",
                "sk",
                "te",
                "fa",
                "lv",
                "bn",
                "sr",
                "az",
                "sl",
                "kn",
                "et",
                "mk",
                "br",
                "eu",
                "is",
                "hy",
                "ne",
                "mn",
                "bs",
                "kk",
                "sq",
                "sw",
                "gl",
                "mr",
                "pa",
                "si",
                "km",
                "sn",
                "yo",
                "so",
                "af",
                "oc",
                "ka",
                "be",
                "tg",
                "sd",
                "gu",
                "am",
                "yi",
                "lo",
                "uz",
                "fo",
                "ht",
                "ps",
                "tk",
                "nn",
                "mt",
                "sa",
                "lb",
                "my",
                "bo",
                "tl",
                "mg",
                "as",
                "tt",
                "haw",
                "ln",
                "ha",
                "ba",
                "jw",
                "su",
                "yue"
              ],
              "default": "en",
              "title": "Language"
            },
            "description": "Language to transcribe"
          },
          {
            "name": "task",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')",
              "enum": [
                "transcribe",
                "translate"
              ],
              "default": "transcribe",
              "title": "Task"
            },
            "description": "whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')"
          },
          {
            "name": "model",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/WhisperModel"
                }
              ],
              "description": "Name of the Whisper model to use",
              "default": "tiny",
              "title": "Model"
            },
            "description": "Name of the Whisper model to use"
          },
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Device"
                }
              ],
              "description": "Device to use for PyTorch inference",
              "default": "cuda",
              "title": "Device"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "device_index",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Device index to use for FasterWhisper inference",
              "default": 0,
              "title": "Device Index"
            },
            "description": "Device index to use for FasterWhisper inference"
          },
          {
            "name": "batch_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "The preferred batch size for inference",
              "default": 8,
              "title": "Batch Size"
            },
            "description": "The preferred batch size for inference"
          },
          {
            "name": "compute_type",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/ComputeType"
                }
              ],
              "description": "Type of computation",
              "default": "float16",
              "title": "Compute Type"
            },
            "description": "Type of computation"
          },
          {
            "name": "temperature",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "temperature to use for sampling",
              "default": 0,
              "title": "Temperature"
            },
            "description": "temperature to use for sampling"
          },
          {
            "name": "beam_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "number of beams in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Beam Size"
            },
            "description": "number of beams in beam search, only applicable when temperature is zero"
          },
          {
            "name": "patience",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "optional patience value to use in beam decoding",
              "default": 1.0,
              "title": "Patience"
            },
            "description": "optional patience value to use in beam decoding"
          },
          {
            "name": "length_penalty",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "optional token length penalty coefficient",
              "default": 1.0,
              "title": "Length Penalty"
            },
            "description": "optional token length penalty coefficient"
          },
          {
            "name": "suppress_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "comma-separated list of token ids to suppress during sampling",
              "default": "-1",
              "title": "Suppress Tokens"
            },
            "description": "comma-separated list of token ids to suppress during sampling"
          },
          {
            "name": "suppress_numerals",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "whether to suppress numeric symbols and currency symbols during sampling",
              "default": false,
              "title": "Suppress Numerals"
            },
            "description": "whether to suppress numeric symbols and currency symbols during sampling"
          },
          {
            "name": "initial_prompt",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "optional text to provide as a prompt for the first window.",
              "title": "Initial Prompt"
            },
            "description": "optional text to provide as a prompt for the first window."
          },
          {
            "name": "compression_ratio_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "if the gzip compression ratio is higher than this value, treat the decoding as failed",
              "default": 2.4,
              "title": "Compression Ratio Threshold"
            },
            "description": "if the gzip compression ratio is higher than this value, treat the decoding as failed"
          },
          {
            "name": "logprob_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "if the average log probability is lower than this value, treat the decoding as failed",
              "default": -1.0,
              "title": "Logprob Threshold"
            },
            "description": "if the average log probability is lower than this value, treat the decoding as failed"
          },
          {
            "name": "no_speech_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "if the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence",
              "default": 0.6,
              "title": "No Speech Threshold"
            },
            "description": "if the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence"
          },
          {
            "name": "vad_onset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected",
              "default": 0.5,
              "title": "Vad Onset"
            },
            "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected"
          },
          {
            "name": "vad_offset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected.",
              "default": 0.363,
              "title": "Vad Offset"
            },
            "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected."
          },
          {
            "name": "threads",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS",
              "default": 0,
              "title": "Threads"
            },
            "description": "number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS"
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_1__Transcribe_service_transcribe_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/align": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "2. Align Transcript",
        "operationId": "2__Align_Transcript_service_align_post",
        "parameters": [
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Device"
                }
              ],
              "description": "Device to use for PyTorch inference",
              "default": "cuda",
              "title": "Device"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "align_model",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "Name of phoneme-level ASR model to do alignment",
              "title": "Align Model"
            },
            "description": "Name of phoneme-level ASR model to do alignment"
          },
          {
            "name": "interpolate_method",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring.",
              "enum": [
                "nearest",
                "linear",
                "ignore"
              ],
              "default": "nearest",
              "title": "Interpolate Method"
            },
            "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring."
          },
          {
            "name": "return_char_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return character-level alignments in the output json file",
              "default": false,
              "title": "Return Char Alignments"
            },
            "description": "Return character-level alignments in the output json file"
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_2__Align_Transcript_service_align_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/diarize": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "3. Diarize",
        "operationId": "3__Diarize_service_diarize_post",
        "parameters": [
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "allOf": [
                {
                  "$ref": "#/components/schemas/Device"
                }
              ],
              "description": "Device to use for PyTorch inference",
              "default": "cuda",
              "title": "Device"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "min_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Minimum number of speakers to in audio file",
              "title": "Min Speakers"
            },
            "description": "Minimum number of speakers to in audio file"
          },
          {
            "name": "max_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Maximum number of speakers to in audio file",
              "title": "Max Speakers"
            },
            "description": "Maximum number of speakers to in audio file"
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_3__Diarize_service_diarize_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/combine": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "4. Combine Transcript And Diarization Result",
        "operationId": "4__Combine_Transcript_and_Diarization_result_service_combine_post",
        "requestBody": {
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_4__Combine_Transcript_and_Diarization_result_service_combine_post"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "Body_1__Transcribe_service_transcribe_post": {
        "properties": {
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File",
            "description": "Audio/video file to transcribe"
          }
        },
        "type": "object",
        "required": [
          "file"
        ],
        "title": "Body_1__Transcribe_service_transcribe_post"
      },
      "Body_2__Align_Transcript_service_align_post": {
        "properties": {
          "transcript": {
            "type": "string",
            "format": "binary",
            "title": "Transcript",
            "description": "Whisper style transcript json file"
          },
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File",
            "description": "Audio/video file which has been transcribed"
          }
        },
        "type": "object",
        "required": [
          "transcript",
          "file"
        ],
        "title": "Body_2__Align_Transcript_service_align_post"
      },
      "Body_3__Diarize_service_diarize_post": {
        "properties": {
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File"
          }
        },
        "type": "object",
        "required": [
          "file"
        ],
        "title": "Body_3__Diarize_service_diarize_post"
      },
      "Body_4__Combine_Transcript_and_Diarization_result_service_combine_post": {
        "properties": {
          "aligned_transcript": {
            "type": "string",
            "format": "binary",
            "title": "Aligned Transcript"
          },
          "diarization_result": {
            "type": "string",
            "format": "binary",
            "title": "Diarization Result"
          }
        },
        "type": "object",
        "required": [
          "aligned_transcript",
          "diarization_result"
        ],
        "title": "Body_4__Combine_Transcript_and_Diarization_result_service_combine_post"
      },
      "Body_speech_to_text_speech_to_text_post": {
        "properties": {
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File"
          }
        },
        "type": "object",
        "required": [
          "file"
        ],
        "title": "Body_speech_to_text_speech_to_text_post"
      },
      "Body_speech_to_text_url_speech_to_text_url_post": {
        "properties": {
          "url": {
            "type": "string",
            "title": "Url"
          }
        },
        "type": "object",
        "required": [
          "url"
        ],
        "title": "Body_speech_to_text_url_speech_to_text_url_post"
      },
      "ComputeType": {
        "type": "string",
        "enum": [
          "float16",
          "float32",
          "int8"
        ],
        "title": "ComputeType"
      },
      "Device": {
        "type": "string",
        "enum": [
          "cuda",
          "cpu"
        ],
        "title": "Device"
      },
      "HTTPValidationError": {
        "properties": {
          "detail": {
            "items": {
              "$ref": "#/components/schemas/ValidationError"
            },
            "type": "array",
            "title": "Detail"
          }
        },
        "type": "object",
        "title": "HTTPValidationError"
      },
      "InterpolateMethod": {
        "type": "string",
        "enum": [
          "nearest",
          "linear",
          "ignore"
        ],
        "title": "InterpolateMethod"
      },
      "LanguageEnum": {
        "type": "string",
        "enum": [
          "en",
          "zh",
          "de",
          "es",
          "ru",
          "ko",
          "fr",
          "ja",
          "pt",
          "tr",
          "pl",
          "ca",
          "nl",
          "ar",
          "sv",
          "it",
          "id",
          "hi",
          "fi",
          "vi",
          "he",
          "uk",
          "el",
          "ms",
          "cs",
          "ro",
          "da",
          "hu",
          "ta",
          "no",
          "th",
          "ur",
          "hr",
          "bg",
          "lt",
          "la",
          "mi",
          "ml",
          "cy",
          "sk",
          "te",
          "fa",
          "lv",
          "bn",
          "sr",
          "az",
          "sl",
          "kn",
          "et",
          "mk",
          "br",
          "eu",
          "is",
          "hy",
          "ne",
          "mn",
          "bs",
          "kk",
          "sq",
          "sw",
          "gl",
          "mr",
          "pa",
          "si",
          "km",
          "sn",
          "yo",
          "so",
          "af",
          "oc",
          "ka",
          "be",
          "tg",
          "sd",
          "gu",
          "am",
          "yi",
          "lo",
          "uz",
          "fo",
          "ht",
          "ps",
          "tk",
          "nn",
          "mt",
          "sa",
          "lb",
          "my",
          "bo",
          "tl",
          "mg",
          "as",
          "tt",
          "haw",
          "ln",
          "ha",
          "ba",
          "jw",
          "su",
          "yue"
        ],
        "title": "LanguageEnum"
      },
      "Metadata": {
        "properties": {
          "task_type": {
            "type": "string",
            "title": "Task Type"
          },
          "task_params": {
            "anyOf": [
              {
                "type": "object"
              },
              {
                "type": "null"
              }
            ],
            "title": "Task Params"
          },
          "language": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Language"
          },
          "file_name": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "File Name"
          },
          "url": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Url"
          },
          "duration": {
            "anyOf": [
              {
                "type": "number"
              },
              {
                "type": "null"
              }
            ],
            "title": "Duration"
          }
        },
        "type": "object",
        "required": [
          "task_type",
          "task_params",
          "language",
          "file_name",
          "url",
          "duration"
        ],
        "title": "Metadata"
      },
      "Response": {
        "properties": {
          "identifier": {
            "type": "string",
            "title": "Identifier"
          },
          "message": {
            "type": "string",
            "title": "Message"
          }
        },
        "type": "object",
        "required": [
          "identifier",
          "message"
        ],
        "title": "Response"
      },
      "Result": {
        "properties": {
          "status": {
            "type": "string",
            "title": "Status"
          },
          "result": {
            "title": "Result"
          },
          "metadata": {
            "$ref": "#/components/schemas/Metadata"
          },
          "error": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Error"
          }
        },
        "type": "object",
        "required": [
          "status",
          "result",
          "metadata",
          "error"
        ],
        "title": "Result"
      },
      "ResultTasks": {
        "properties": {
          "tasks": {
            "items": {
              "$ref": "#/components/schemas/TaskSimple"
            },
            "type": "array",
            "title": "Tasks"
          }
        },
        "type": "object",
        "required": [
          "tasks"
        ],
        "title": "ResultTasks"
      },
      "TaskEnum": {
        "type": "string",
        "enum": [
          "transcribe",
          "translate"
        ],
        "title": "TaskEnum"
      },
      "TaskSimple": {
        "properties": {
          "identifier": {
            "type": "string",
            "title": "Identifier"
          },
          "status": {
            "type": "string",
            "title": "Status"
          },
          "task_type": {
            "type": "string",
            "title": "Task Type"
          }
        },
        "type": "object",
        "required": [
          "identifier",
          "status",
          "task_type"
        ],
        "title": "TaskSimple"
      },
      "ValidationError": {
        "properties": {
          "loc": {
            "items": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "integer"
                }
              ]
            },
            "type": "array",
            "title": "Location"
          },
          "msg": {
            "type": "string",
            "title": "Message"
          },
          "type": {
            "type": "string",
            "title": "Error Type"
          }
        },
        "type": "object",
        "required": [
          "loc",
          "msg",
          "type"
        ],
        "title": "ValidationError"
      },
      "WhisperModel": {
        "type": "string",
        "enum": [
          "tiny",
          "tiny.en",
          "base",
          "base.en",
          "small",
          "small.en",
          "medium",
          "medium.en",
          "large",
          "large-v1",
          "large-v2",
          "large-v3"
        ],
        "title": "WhisperModel"
      }
    }
  },
  "tags": [
    {
      "name": "Speech-2-Text",
      "description": "Operations related to transcript"
    },
    {
      "name": "Speech-2-Text services",
      "description": "Individual services for transcript"
    },
    {
      "name": "Tasks Management",
      "description": "Manage tasks."
    }
  ]
}