{
  "openapi": "3.1.0",
  "info": {
    "title": "whisperX REST service",
    "description": "\n    # whisperX RESTful API\n\n    Welcome to the whisperX RESTful API! This API provides a suite of audio processing services to enhance and analyze your audio content.\n\n    ## Documentation:\n\n    For detailed information on request and response formats, consult the [WhisperX Documentation](https://github.com/m-bain/whisperX).\n\n    ## Services:\n\n    Speech-2-Text provides a suite of audio processing services to enhance and analyze your audio content. The following services are available:\n\n    1. Transcribe: Transcribe an audio/video  file into text.\n    2. Align: Align the transcript to the audio/video file.\n    3. Diarize: Diarize an audio/video file into speakers.\n    4. Combine Transcript and Diarization: Combine the transcript and diarization results.\n\n    ## Supported file extensions:\n    AUDIO_EXTENSIONS = {'.wav', '.aac', '.mp3', '.awb', '.amr', '.oga', '.ogg', '.wma', '.m4a'}\n\n    VIDEO_EXTENSIONS = {'.mp4', '.mov', '.mkv', '.avi', '.wmv'}\n\n    ",
    "version": "0.0.1"
  },
  "paths": {
    "/speech-to-text": {
      "post": {
        "tags": [
          "Speech-2-Text"
        ],
        "summary": "Speech To Text",
        "description": "Process an uploaded audio file for speech-to-text conversion.\n\nArgs:\n    background_tasks (BackgroundTasks): Background tasks dependency.\n    model_params (WhisperModelParams): Whisper model parameters.\n    align_params (AlignmentParams): Alignment parameters.\n    diarize_params (DiarizationParams): Diarization parameters.\n    asr_options_params (ASROptions): ASR options parameters.\n    vad_options_params (VADOptions): VAD options parameters.\n    file (UploadFile): Uploaded audio file.\n    session (Session): Database session dependency.\n\nReturns:\n    Response: Confirmation message of task queuing.",
        "operationId": "speech_to_text_speech_to_text_post",
        "parameters": [
          {
            "name": "language",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "Language to transcribe",
              "enum": [
                "en",
                "zh",
                "de",
                "es",
                "ru",
                "ko",
                "fr",
                "ja",
                "pt",
                "tr",
                "pl",
                "ca",
                "nl",
                "ar",
                "sv",
                "it",
                "id",
                "hi",
                "fi",
                "vi",
                "he",
                "uk",
                "el",
                "ms",
                "cs",
                "ro",
                "da",
                "hu",
                "ta",
                "no",
                "th",
                "ur",
                "hr",
                "bg",
                "lt",
                "la",
                "mi",
                "ml",
                "cy",
                "sk",
                "te",
                "fa",
                "lv",
                "bn",
                "sr",
                "az",
                "sl",
                "kn",
                "et",
                "mk",
                "br",
                "eu",
                "is",
                "hy",
                "ne",
                "mn",
                "bs",
                "kk",
                "sq",
                "sw",
                "gl",
                "mr",
                "pa",
                "si",
                "km",
                "sn",
                "yo",
                "so",
                "af",
                "oc",
                "ka",
                "be",
                "tg",
                "sd",
                "gu",
                "am",
                "yi",
                "lo",
                "uz",
                "fo",
                "ht",
                "ps",
                "tk",
                "nn",
                "mt",
                "sa",
                "lb",
                "my",
                "bo",
                "tl",
                "mg",
                "as",
                "tt",
                "haw",
                "ln",
                "ha",
                "ba",
                "jw",
                "su",
                "yue"
              ],
              "default": "en",
              "title": "Language"
            },
            "description": "Language to transcribe"
          },
          {
            "name": "task",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/TaskEnum",
              "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')",
              "default": "transcribe"
            },
            "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')"
          },
          {
            "name": "model",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/WhisperModel",
              "description": "Name of the Whisper model to use",
              "default": "tiny"
            },
            "description": "Name of the Whisper model to use"
          },
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/Device",
              "description": "Device to use for PyTorch inference",
              "default": "cuda"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "device_index",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Device index to use for FasterWhisper inference",
              "default": 0,
              "title": "Device Index"
            },
            "description": "Device index to use for FasterWhisper inference"
          },
          {
            "name": "threads",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS",
              "default": 0,
              "title": "Threads"
            },
            "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS"
          },
          {
            "name": "batch_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "The preferred batch size for inference",
              "default": 8,
              "title": "Batch Size"
            },
            "description": "The preferred batch size for inference"
          },
          {
            "name": "chunk_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long.",
              "default": 20,
              "title": "Chunk Size"
            },
            "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long."
          },
          {
            "name": "compute_type",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/ComputeType",
              "description": "Type of computation",
              "default": "float16"
            },
            "description": "Type of computation"
          },
          {
            "name": "align_model",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Name of phoneme-level ASR model to do alignment",
              "title": "Align Model"
            },
            "description": "Name of phoneme-level ASR model to do alignment"
          },
          {
            "name": "interpolate_method",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/InterpolateMethod",
              "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring.",
              "default": "nearest"
            },
            "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring."
          },
          {
            "name": "return_char_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return character-level alignments in the output json file",
              "default": false,
              "title": "Return Char Alignments"
            },
            "description": "Return character-level alignments in the output json file"
          },
          {
            "name": "min_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Minimum number of speakers to in audio file",
              "title": "Min Speakers"
            },
            "description": "Minimum number of speakers to in audio file"
          },
          {
            "name": "max_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Maximum number of speakers to in audio file",
              "title": "Max Speakers"
            },
            "description": "Maximum number of speakers to in audio file"
          },
          {
            "name": "beam_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Beam Size"
            },
            "description": "Number of beams in beam search, only applicable when temperature is zero"
          },
          {
            "name": "best_of",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams to keep in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Best Of"
            },
            "description": "Number of beams to keep in beam search, only applicable when temperature is zero"
          },
          {
            "name": "patience",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional patience value to use in beam decoding",
              "default": 1.0,
              "title": "Patience"
            },
            "description": "Optional patience value to use in beam decoding"
          },
          {
            "name": "length_penalty",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional token length penalty coefficient",
              "default": 1.0,
              "title": "Length Penalty"
            },
            "description": "Optional token length penalty coefficient"
          },
          {
            "name": "temperatures",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Temperature to use for sampling",
              "default": 0.0,
              "title": "Temperatures"
            },
            "description": "Temperature to use for sampling"
          },
          {
            "name": "compression_ratio_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed",
              "default": 2.4,
              "title": "Compression Ratio Threshold"
            },
            "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed"
          },
          {
            "name": "log_prob_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the average log probability is lower than this value, treat the decoding as failed",
              "default": -1.0,
              "title": "Log Prob Threshold"
            },
            "description": "If the average log probability is lower than this value, treat the decoding as failed"
          },
          {
            "name": "no_speech_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence",
              "default": 0.6,
              "title": "No Speech Threshold"
            },
            "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence"
          },
          {
            "name": "initial_prompt",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Optional text to provide as a prompt for the first window.",
              "title": "Initial Prompt"
            },
            "description": "Optional text to provide as a prompt for the first window."
          },
          {
            "name": "suppress_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "array",
              "items": {
                "type": "integer"
              },
              "description": "Comma-separated list of token ids to suppress during sampling",
              "default": [
                -1
              ],
              "title": "Suppress Tokens"
            },
            "description": "Comma-separated list of token ids to suppress during sampling"
          },
          {
            "name": "suppress_numerals",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "boolean"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Whether to suppress numeric symbols and currency symbols during sampling",
              "default": false,
              "title": "Suppress Numerals"
            },
            "description": "Whether to suppress numeric symbols and currency symbols during sampling"
          },
          {
            "name": "hotwords",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Hotwords related prompt applied before each transcription window",
              "title": "Hotwords"
            },
            "description": "Hotwords related prompt applied before each transcription window"
          },
          {
            "name": "vad_onset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected",
              "default": 0.5,
              "title": "Vad Onset"
            },
            "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected"
          },
          {
            "name": "vad_offset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected.",
              "default": 0.363,
              "title": "Vad Offset"
            },
            "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected."
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_speech_to_text_speech_to_text_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/speech-to-text-url": {
      "post": {
        "tags": [
          "Speech-2-Text"
        ],
        "summary": "Speech To Text Url",
        "description": "Process an audio file from a URL for speech-to-text conversion.\n\nArgs:\n    background_tasks (BackgroundTasks): Background tasks dependency.\n    model_params (WhisperModelParams): Whisper model parameters.\n    align_params (AlignmentParams): Alignment parameters.\n    diarize_params (DiarizationParams): Diarization parameters.\n    asr_options_params (ASROptions): ASR options parameters.\n    vad_options_params (VADOptions): VAD options parameters.\n    url (str): URL of the audio file.\n    session (Session): Database session dependency.\n\nReturns:\n    Response: Confirmation message of task queuing.",
        "operationId": "speech_to_text_url_speech_to_text_url_post",
        "parameters": [
          {
            "name": "language",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "Language to transcribe",
              "enum": [
                "en",
                "zh",
                "de",
                "es",
                "ru",
                "ko",
                "fr",
                "ja",
                "pt",
                "tr",
                "pl",
                "ca",
                "nl",
                "ar",
                "sv",
                "it",
                "id",
                "hi",
                "fi",
                "vi",
                "he",
                "uk",
                "el",
                "ms",
                "cs",
                "ro",
                "da",
                "hu",
                "ta",
                "no",
                "th",
                "ur",
                "hr",
                "bg",
                "lt",
                "la",
                "mi",
                "ml",
                "cy",
                "sk",
                "te",
                "fa",
                "lv",
                "bn",
                "sr",
                "az",
                "sl",
                "kn",
                "et",
                "mk",
                "br",
                "eu",
                "is",
                "hy",
                "ne",
                "mn",
                "bs",
                "kk",
                "sq",
                "sw",
                "gl",
                "mr",
                "pa",
                "si",
                "km",
                "sn",
                "yo",
                "so",
                "af",
                "oc",
                "ka",
                "be",
                "tg",
                "sd",
                "gu",
                "am",
                "yi",
                "lo",
                "uz",
                "fo",
                "ht",
                "ps",
                "tk",
                "nn",
                "mt",
                "sa",
                "lb",
                "my",
                "bo",
                "tl",
                "mg",
                "as",
                "tt",
                "haw",
                "ln",
                "ha",
                "ba",
                "jw",
                "su",
                "yue"
              ],
              "default": "en",
              "title": "Language"
            },
            "description": "Language to transcribe"
          },
          {
            "name": "task",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/TaskEnum",
              "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')",
              "default": "transcribe"
            },
            "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')"
          },
          {
            "name": "model",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/WhisperModel",
              "description": "Name of the Whisper model to use",
              "default": "tiny"
            },
            "description": "Name of the Whisper model to use"
          },
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/Device",
              "description": "Device to use for PyTorch inference",
              "default": "cuda"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "device_index",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Device index to use for FasterWhisper inference",
              "default": 0,
              "title": "Device Index"
            },
            "description": "Device index to use for FasterWhisper inference"
          },
          {
            "name": "threads",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS",
              "default": 0,
              "title": "Threads"
            },
            "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS"
          },
          {
            "name": "batch_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "The preferred batch size for inference",
              "default": 8,
              "title": "Batch Size"
            },
            "description": "The preferred batch size for inference"
          },
          {
            "name": "chunk_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long.",
              "default": 20,
              "title": "Chunk Size"
            },
            "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long."
          },
          {
            "name": "compute_type",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/ComputeType",
              "description": "Type of computation",
              "default": "float16"
            },
            "description": "Type of computation"
          },
          {
            "name": "align_model",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Name of phoneme-level ASR model to do alignment",
              "title": "Align Model"
            },
            "description": "Name of phoneme-level ASR model to do alignment"
          },
          {
            "name": "interpolate_method",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/InterpolateMethod",
              "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring.",
              "default": "nearest"
            },
            "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring."
          },
          {
            "name": "return_char_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return character-level alignments in the output json file",
              "default": false,
              "title": "Return Char Alignments"
            },
            "description": "Return character-level alignments in the output json file"
          },
          {
            "name": "min_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Minimum number of speakers to in audio file",
              "title": "Min Speakers"
            },
            "description": "Minimum number of speakers to in audio file"
          },
          {
            "name": "max_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Maximum number of speakers to in audio file",
              "title": "Max Speakers"
            },
            "description": "Maximum number of speakers to in audio file"
          },
          {
            "name": "beam_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Beam Size"
            },
            "description": "Number of beams in beam search, only applicable when temperature is zero"
          },
          {
            "name": "best_of",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams to keep in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Best Of"
            },
            "description": "Number of beams to keep in beam search, only applicable when temperature is zero"
          },
          {
            "name": "patience",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional patience value to use in beam decoding",
              "default": 1.0,
              "title": "Patience"
            },
            "description": "Optional patience value to use in beam decoding"
          },
          {
            "name": "length_penalty",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional token length penalty coefficient",
              "default": 1.0,
              "title": "Length Penalty"
            },
            "description": "Optional token length penalty coefficient"
          },
          {
            "name": "temperatures",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Temperature to use for sampling",
              "default": 0.0,
              "title": "Temperatures"
            },
            "description": "Temperature to use for sampling"
          },
          {
            "name": "compression_ratio_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed",
              "default": 2.4,
              "title": "Compression Ratio Threshold"
            },
            "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed"
          },
          {
            "name": "log_prob_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the average log probability is lower than this value, treat the decoding as failed",
              "default": -1.0,
              "title": "Log Prob Threshold"
            },
            "description": "If the average log probability is lower than this value, treat the decoding as failed"
          },
          {
            "name": "no_speech_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence",
              "default": 0.6,
              "title": "No Speech Threshold"
            },
            "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence"
          },
          {
            "name": "initial_prompt",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Optional text to provide as a prompt for the first window.",
              "title": "Initial Prompt"
            },
            "description": "Optional text to provide as a prompt for the first window."
          },
          {
            "name": "suppress_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "array",
              "items": {
                "type": "integer"
              },
              "description": "Comma-separated list of token ids to suppress during sampling",
              "default": [
                -1
              ],
              "title": "Suppress Tokens"
            },
            "description": "Comma-separated list of token ids to suppress during sampling"
          },
          {
            "name": "suppress_numerals",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "boolean"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Whether to suppress numeric symbols and currency symbols during sampling",
              "default": false,
              "title": "Suppress Numerals"
            },
            "description": "Whether to suppress numeric symbols and currency symbols during sampling"
          },
          {
            "name": "hotwords",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Hotwords related prompt applied before each transcription window",
              "title": "Hotwords"
            },
            "description": "Hotwords related prompt applied before each transcription window"
          },
          {
            "name": "vad_onset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected",
              "default": 0.5,
              "title": "Vad Onset"
            },
            "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected"
          },
          {
            "name": "vad_offset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected.",
              "default": 0.363,
              "title": "Vad Offset"
            },
            "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected."
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/x-www-form-urlencoded": {
              "schema": {
                "$ref": "#/components/schemas/Body_speech_to_text_url_speech_to_text_url_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/task/all": {
      "get": {
        "tags": [
          "Tasks Management"
        ],
        "summary": "Get All Tasks Status",
        "description": "Retrieve the status of all tasks.\n\nArgs:\n    session (Session): Database session dependency.\n\nReturns:\n    ResultTasks: The status of all tasks.",
        "operationId": "get_all_tasks_status_task_all_get",
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ResultTasks"
                }
              }
            }
          }
        }
      }
    },
    "/task/{identifier}": {
      "get": {
        "tags": [
          "Tasks Management"
        ],
        "summary": "Get Transcription Status",
        "description": "Retrieve the status of a specific task by its identifier.\n\nArgs:\n    identifier (str): The identifier of the task.\n    session (Session): Database session dependency.\n\nReturns:\n    Result: The status of the task.\n\nRaises:\n    HTTPException: If the identifier is not found.",
        "operationId": "get_transcription_status_task__identifier__get",
        "parameters": [
          {
            "name": "identifier",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string",
              "title": "Identifier"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Result"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/task/{identifier}/delete": {
      "delete": {
        "tags": [
          "Tasks Management"
        ],
        "summary": "Delete Task",
        "description": "Delete a specific task by its identifier.\n\nArgs:\n    identifier (str): The identifier of the task.\n    session (Session): Database session dependency.\n\nReturns:\n    Response: Confirmation message of task deletion.\n\nRaises:\n    HTTPException: If the task is not found.",
        "operationId": "delete_task_task__identifier__delete_delete",
        "parameters": [
          {
            "name": "identifier",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string",
              "title": "Identifier"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/transcribe": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "1. Transcribe",
        "description": "Transcribe an uploaded audio file.\n\nArgs:\n    background_tasks (BackgroundTasks): Background tasks dependency.\n    model_params (WhisperModelParams): Whisper model parameters.\n    asr_options_params (ASROptions): ASR options parameters.\n    vad_options_params (VADOptions): VAD options parameters.\n    file (UploadFile): Uploaded audio file.\n    session (Session): Database session dependency.\n\nReturns:\n    Response: Confirmation message of task queuing.",
        "operationId": "1__Transcribe_service_transcribe_post",
        "parameters": [
          {
            "name": "language",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "Language to transcribe",
              "enum": [
                "en",
                "zh",
                "de",
                "es",
                "ru",
                "ko",
                "fr",
                "ja",
                "pt",
                "tr",
                "pl",
                "ca",
                "nl",
                "ar",
                "sv",
                "it",
                "id",
                "hi",
                "fi",
                "vi",
                "he",
                "uk",
                "el",
                "ms",
                "cs",
                "ro",
                "da",
                "hu",
                "ta",
                "no",
                "th",
                "ur",
                "hr",
                "bg",
                "lt",
                "la",
                "mi",
                "ml",
                "cy",
                "sk",
                "te",
                "fa",
                "lv",
                "bn",
                "sr",
                "az",
                "sl",
                "kn",
                "et",
                "mk",
                "br",
                "eu",
                "is",
                "hy",
                "ne",
                "mn",
                "bs",
                "kk",
                "sq",
                "sw",
                "gl",
                "mr",
                "pa",
                "si",
                "km",
                "sn",
                "yo",
                "so",
                "af",
                "oc",
                "ka",
                "be",
                "tg",
                "sd",
                "gu",
                "am",
                "yi",
                "lo",
                "uz",
                "fo",
                "ht",
                "ps",
                "tk",
                "nn",
                "mt",
                "sa",
                "lb",
                "my",
                "bo",
                "tl",
                "mg",
                "as",
                "tt",
                "haw",
                "ln",
                "ha",
                "ba",
                "jw",
                "su",
                "yue"
              ],
              "default": "en",
              "title": "Language"
            },
            "description": "Language to transcribe"
          },
          {
            "name": "task",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/TaskEnum",
              "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')",
              "default": "transcribe"
            },
            "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')"
          },
          {
            "name": "model",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/WhisperModel",
              "description": "Name of the Whisper model to use",
              "default": "tiny"
            },
            "description": "Name of the Whisper model to use"
          },
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/Device",
              "description": "Device to use for PyTorch inference",
              "default": "cuda"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "device_index",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Device index to use for FasterWhisper inference",
              "default": 0,
              "title": "Device Index"
            },
            "description": "Device index to use for FasterWhisper inference"
          },
          {
            "name": "threads",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS",
              "default": 0,
              "title": "Threads"
            },
            "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS"
          },
          {
            "name": "batch_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "The preferred batch size for inference",
              "default": 8,
              "title": "Batch Size"
            },
            "description": "The preferred batch size for inference"
          },
          {
            "name": "chunk_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long.",
              "default": 20,
              "title": "Chunk Size"
            },
            "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long."
          },
          {
            "name": "compute_type",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/ComputeType",
              "description": "Type of computation",
              "default": "float16"
            },
            "description": "Type of computation"
          },
          {
            "name": "beam_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Beam Size"
            },
            "description": "Number of beams in beam search, only applicable when temperature is zero"
          },
          {
            "name": "best_of",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams to keep in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Best Of"
            },
            "description": "Number of beams to keep in beam search, only applicable when temperature is zero"
          },
          {
            "name": "patience",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional patience value to use in beam decoding",
              "default": 1.0,
              "title": "Patience"
            },
            "description": "Optional patience value to use in beam decoding"
          },
          {
            "name": "length_penalty",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional token length penalty coefficient",
              "default": 1.0,
              "title": "Length Penalty"
            },
            "description": "Optional token length penalty coefficient"
          },
          {
            "name": "temperatures",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Temperature to use for sampling",
              "default": 0.0,
              "title": "Temperatures"
            },
            "description": "Temperature to use for sampling"
          },
          {
            "name": "compression_ratio_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed",
              "default": 2.4,
              "title": "Compression Ratio Threshold"
            },
            "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed"
          },
          {
            "name": "log_prob_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the average log probability is lower than this value, treat the decoding as failed",
              "default": -1.0,
              "title": "Log Prob Threshold"
            },
            "description": "If the average log probability is lower than this value, treat the decoding as failed"
          },
          {
            "name": "no_speech_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence",
              "default": 0.6,
              "title": "No Speech Threshold"
            },
            "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence"
          },
          {
            "name": "initial_prompt",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Optional text to provide as a prompt for the first window.",
              "title": "Initial Prompt"
            },
            "description": "Optional text to provide as a prompt for the first window."
          },
          {
            "name": "suppress_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "array",
              "items": {
                "type": "integer"
              },
              "description": "Comma-separated list of token ids to suppress during sampling",
              "default": [
                -1
              ],
              "title": "Suppress Tokens"
            },
            "description": "Comma-separated list of token ids to suppress during sampling"
          },
          {
            "name": "suppress_numerals",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "boolean"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Whether to suppress numeric symbols and currency symbols during sampling",
              "default": false,
              "title": "Suppress Numerals"
            },
            "description": "Whether to suppress numeric symbols and currency symbols during sampling"
          },
          {
            "name": "hotwords",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Hotwords related prompt applied before each transcription window",
              "title": "Hotwords"
            },
            "description": "Hotwords related prompt applied before each transcription window"
          },
          {
            "name": "vad_onset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected",
              "default": 0.5,
              "title": "Vad Onset"
            },
            "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected"
          },
          {
            "name": "vad_offset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected.",
              "default": 0.363,
              "title": "Vad Offset"
            },
            "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected."
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_1__Transcribe_service_transcribe_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/align": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "2. Align Transcript",
        "description": "Align a transcript with an audio file.\n\nArgs:\n    background_tasks (BackgroundTasks): Background tasks dependency.\n    transcript (UploadFile): Uploaded transcript file.\n    file (UploadFile): Uploaded audio file.\n    device (Device): Device for PyTorch inference.\n    align_params (AlignmentParams): Alignment parameters.\n    session (Session): Database session dependency.\n\nReturns:\n    Response: Confirmation message of task queuing.",
        "operationId": "2__Align_Transcript_service_align_post",
        "parameters": [
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/Device",
              "description": "Device to use for PyTorch inference",
              "default": "cuda"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "align_model",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Name of phoneme-level ASR model to do alignment",
              "title": "Align Model"
            },
            "description": "Name of phoneme-level ASR model to do alignment"
          },
          {
            "name": "interpolate_method",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/InterpolateMethod",
              "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring.",
              "default": "nearest"
            },
            "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring."
          },
          {
            "name": "return_char_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return character-level alignments in the output json file",
              "default": false,
              "title": "Return Char Alignments"
            },
            "description": "Return character-level alignments in the output json file"
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_2__Align_Transcript_service_align_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/diarize": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "3. Diarize",
        "description": "Perform diarization on an uploaded audio file.\n\nArgs:\n    background_tasks (BackgroundTasks): Background tasks dependency.\n    file (UploadFile): Uploaded audio file.\n    session (Session): Database session dependency.\n    device (Device): Device for PyTorch inference.\n    diarize_params (DiarizationParams): Diarization parameters.\n\nReturns:\n    Response: Confirmation message of task queuing.",
        "operationId": "3__Diarize_service_diarize_post",
        "parameters": [
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/Device",
              "description": "Device to use for PyTorch inference",
              "default": "cuda"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "min_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Minimum number of speakers to in audio file",
              "title": "Min Speakers"
            },
            "description": "Minimum number of speakers to in audio file"
          },
          {
            "name": "max_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Maximum number of speakers to in audio file",
              "title": "Max Speakers"
            },
            "description": "Maximum number of speakers to in audio file"
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_3__Diarize_service_diarize_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/combine": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "4. Combine Transcript And Diarization Result",
        "description": "Combine a transcript with diarization results.\n\nArgs:\n    background_tasks (BackgroundTasks): Background tasks dependency.\n    aligned_transcript (UploadFile): Uploaded aligned transcript file.\n    diarization_result (UploadFile): Uploaded diarization result file.\n    session (Session): Database session dependency.\n\nReturns:\n    Response: Confirmation message of task queuing.",
        "operationId": "4__Combine_Transcript_and_Diarization_result_service_combine_post",
        "requestBody": {
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_4__Combine_Transcript_and_Diarization_result_service_combine_post"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/health": {
      "get": {
        "tags": [
          "Health"
        ],
        "summary": "Simple health check",
        "description": "Verify the service is up and running.\n\nReturns a simple status response to confirm the API service is operational.",
        "operationId": "health_check_health_get",
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          }
        }
      }
    },
    "/health/live": {
      "get": {
        "tags": [
          "Health"
        ],
        "summary": "Liveness check",
        "description": "Check if the application is running.\n\nUsed by orchestration systems like Kubernetes to detect if the app is alive.\nReturns timestamp along with status information.",
        "operationId": "liveness_check_health_live_get",
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          }
        }
      }
    },
    "/health/ready": {
      "get": {
        "tags": [
          "Health"
        ],
        "summary": "Readiness check",
        "description": "Check if the application is ready to accept requests.\n\nVerifies dependencies like the database are connected and ready.\nReturns HTTP 200 if all systems are operational, HTTP 503 if any dependency\nhas failed.",
        "operationId": "readiness_check_health_ready_get",
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "Body_1__Transcribe_service_transcribe_post": {
        "properties": {
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File",
            "description": "Audio/video file to transcribe"
          }
        },
        "type": "object",
        "required": [
          "file"
        ],
        "title": "Body_1__Transcribe_service_transcribe_post"
      },
      "Body_2__Align_Transcript_service_align_post": {
        "properties": {
          "transcript": {
            "type": "string",
            "format": "binary",
            "title": "Transcript",
            "description": "Whisper style transcript json file"
          },
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File",
            "description": "Audio/video file which has been transcribed"
          }
        },
        "type": "object",
        "required": [
          "transcript",
          "file"
        ],
        "title": "Body_2__Align_Transcript_service_align_post"
      },
      "Body_3__Diarize_service_diarize_post": {
        "properties": {
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File"
          }
        },
        "type": "object",
        "required": [
          "file"
        ],
        "title": "Body_3__Diarize_service_diarize_post"
      },
      "Body_4__Combine_Transcript_and_Diarization_result_service_combine_post": {
        "properties": {
          "aligned_transcript": {
            "type": "string",
            "format": "binary",
            "title": "Aligned Transcript"
          },
          "diarization_result": {
            "type": "string",
            "format": "binary",
            "title": "Diarization Result"
          }
        },
        "type": "object",
        "required": [
          "aligned_transcript",
          "diarization_result"
        ],
        "title": "Body_4__Combine_Transcript_and_Diarization_result_service_combine_post"
      },
      "Body_speech_to_text_speech_to_text_post": {
        "properties": {
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File"
          }
        },
        "type": "object",
        "required": [
          "file"
        ],
        "title": "Body_speech_to_text_speech_to_text_post"
      },
      "Body_speech_to_text_url_speech_to_text_url_post": {
        "properties": {
          "url": {
            "type": "string",
            "title": "Url"
          }
        },
        "type": "object",
        "required": [
          "url"
        ],
        "title": "Body_speech_to_text_url_speech_to_text_url_post"
      },
      "ComputeType": {
        "type": "string",
        "enum": [
          "float16",
          "float32",
          "int8"
        ],
        "title": "ComputeType",
        "description": "Enum for compute types."
      },
      "Device": {
        "type": "string",
        "enum": [
          "cuda",
          "cpu"
        ],
        "title": "Device",
        "description": "Enum for device types."
      },
      "HTTPValidationError": {
        "properties": {
          "detail": {
            "items": {
              "$ref": "#/components/schemas/ValidationError"
            },
            "type": "array",
            "title": "Detail"
          }
        },
        "type": "object",
        "title": "HTTPValidationError"
      },
      "InterpolateMethod": {
        "type": "string",
        "enum": [
          "nearest",
          "linear",
          "ignore"
        ],
        "title": "InterpolateMethod",
        "description": "Enum for interpolation methods."
      },
      "Metadata": {
        "properties": {
          "task_type": {
            "type": "string",
            "title": "Task Type"
          },
          "task_params": {
            "anyOf": [
              {
                "additionalProperties": true,
                "type": "object"
              },
              {
                "type": "null"
              }
            ],
            "title": "Task Params"
          },
          "language": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Language"
          },
          "file_name": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "File Name"
          },
          "url": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Url"
          },
          "duration": {
            "anyOf": [
              {
                "type": "number"
              },
              {
                "type": "null"
              }
            ],
            "title": "Duration"
          },
          "audio_duration": {
            "anyOf": [
              {
                "type": "number"
              },
              {
                "type": "null"
              }
            ],
            "title": "Audio Duration"
          },
          "start_time": {
            "anyOf": [
              {
                "type": "string",
                "format": "date-time"
              },
              {
                "type": "null"
              }
            ],
            "title": "Start Time"
          },
          "end_time": {
            "anyOf": [
              {
                "type": "string",
                "format": "date-time"
              },
              {
                "type": "null"
              }
            ],
            "title": "End Time"
          }
        },
        "type": "object",
        "required": [
          "task_type",
          "task_params",
          "language",
          "file_name",
          "url",
          "duration"
        ],
        "title": "Metadata",
        "description": "Metadata model for task information."
      },
      "Response": {
        "properties": {
          "identifier": {
            "type": "string",
            "title": "Identifier"
          },
          "message": {
            "type": "string",
            "title": "Message"
          }
        },
        "type": "object",
        "required": [
          "identifier",
          "message"
        ],
        "title": "Response",
        "description": "Response model for API responses."
      },
      "Result": {
        "properties": {
          "status": {
            "type": "string",
            "title": "Status"
          },
          "result": {
            "title": "Result"
          },
          "metadata": {
            "$ref": "#/components/schemas/Metadata"
          },
          "error": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "title": "Error"
          }
        },
        "type": "object",
        "required": [
          "status",
          "result",
          "metadata",
          "error"
        ],
        "title": "Result",
        "description": "Model for a result with status, result data, metadata, and optional error."
      },
      "ResultTasks": {
        "properties": {
          "tasks": {
            "items": {
              "$ref": "#/components/schemas/TaskSimple"
            },
            "type": "array",
            "title": "Tasks"
          }
        },
        "type": "object",
        "required": [
          "tasks"
        ],
        "title": "ResultTasks",
        "description": "Model for a list of simple tasks."
      },
      "TaskEnum": {
        "type": "string",
        "enum": [
          "transcribe",
          "translate"
        ],
        "title": "TaskEnum",
        "description": "Enum for task types."
      },
      "TaskSimple": {
        "properties": {
          "identifier": {
            "type": "string",
            "title": "Identifier"
          },
          "status": {
            "type": "string",
            "title": "Status"
          },
          "task_type": {
            "type": "string",
            "title": "Task Type"
          }
        },
        "type": "object",
        "required": [
          "identifier",
          "status",
          "task_type"
        ],
        "title": "TaskSimple",
        "description": "Simple task model with basic task information."
      },
      "ValidationError": {
        "properties": {
          "loc": {
            "items": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "integer"
                }
              ]
            },
            "type": "array",
            "title": "Location"
          },
          "msg": {
            "type": "string",
            "title": "Message"
          },
          "type": {
            "type": "string",
            "title": "Error Type"
          }
        },
        "type": "object",
        "required": [
          "loc",
          "msg",
          "type"
        ],
        "title": "ValidationError"
      },
      "WhisperModel": {
        "type": "string",
        "enum": [
          "tiny",
          "tiny.en",
          "base",
          "base.en",
          "small",
          "small.en",
          "medium",
          "medium.en",
          "large",
          "large-v1",
          "large-v2",
          "large-v3",
          "large-v3-turbo",
          "distil-large-v2",
          "distil-medium.en",
          "distil-small.en",
          "distil-large-v3",
          "nyrahealth/faster_CrisperWhisper"
        ],
        "title": "WhisperModel",
        "description": "Enum for Whisper model types."
      }
    }
  },
  "tags": [
    {
      "name": "Speech-2-Text",
      "description": "Operations related to transcript"
    },
    {
      "name": "Speech-2-Text services",
      "description": "Individual services for transcript"
    },
    {
      "name": "Tasks Management",
      "description": "Manage tasks."
    },
    {
      "name": "Health",
      "description": "Health check endpoints to monitor application status"
    }
  ]
}
